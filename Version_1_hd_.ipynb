{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac165f4-7b67-43d8-9ca5-2fbb39fcd99b",
   "metadata": {},
   "source": [
    "### Importing required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca0a93-13c5-4e10-9e1a-09db5809dc5a",
   "metadata": {},
   "source": [
    "The data is collected from yahoo finance on a daily basis which can be altered depending on the requirement . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a961298d-7f6f-478e-9f9d-f9d2b863ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (0.1.74)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from yfinance) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from yfinance) (1.21.5)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from yfinance) (4.8.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from yfinance) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.26->yfinance) (3.3)\n",
      "Requirement already satisfied: pandas_datareader in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas_datareader) (2.27.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas_datareader) (4.8.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas_datareader) (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_datareader) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2.0.4)\n",
      "Requirement already satisfied: scikeras in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikeras) (4.11.3)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from importlib-metadata>=3->scikeras) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from imbalanced-learn) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Collecting TA-Lib\n",
      "  Using cached TA-Lib-0.4.25.tar.gz (271 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages (from TA-Lib) (1.21.5)\n",
      "Building wheels for collected packages: TA-Lib\n",
      "  Building wheel for TA-Lib (PEP 517): started\n",
      "  Building wheel for TA-Lib (PEP 517): finished with status 'error'\n",
      "Failed to build TA-Lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\henry\\anaconda3\\envs\\dev1\\python.exe' 'C:\\Users\\henry\\anaconda3\\envs\\dev1\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\henry\\AppData\\Local\\Temp\\tmpjl4m0k9z'\n",
      "       cwd: C:\\Users\\henry\\AppData\\Local\\Temp\\pip-install-lks_z20a\\ta-lib_f950ad26c1774d9a9c0f8e0dcc5717e2\n",
      "  Complete output (21 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-37\n",
      "  creating build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\abstract.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\deprecated.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\stream.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_abstract.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_data.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_func.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_pandas.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_polars.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\test_stream.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  copying talib\\__init__.py -> build\\lib.win-amd64-cpython-37\\talib\n",
      "  running build_ext\n",
      "  building 'talib._ta_lib' extension\n",
      "  setup.py:77: UserWarning: Cannot find ta-lib library, installation may fail.\n",
      "    warnings.warn('Cannot find ta-lib library, installation may fail.')\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for TA-Lib\n",
      "ERROR: Could not build wheels for TA-Lib which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "#Installing Yahoo Finance\n",
    "!pip install yfinance\n",
    "!pip install pandas_datareader\n",
    "!pip install scikeras\n",
    "!pip install imbalanced-learn\n",
    "!pip install xgboost\n",
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595710a5-2f57-4e65-9922-b4c1767d34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, datetime\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import alpaca_trade_api as tradeapi\n",
    "import os\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as pdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from itertools import product\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0161751-7dcb-4117-8c0d-8b5491b7441a",
   "metadata": {},
   "source": [
    "### Importing Data from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fab536-5c03-482d-bbf1-a27d274b20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your desired ticker NDAQ\n"
     ]
    }
   ],
   "source": [
    "#Collecting desired ticker from user\n",
    "ticker = input(\"Please enter your desired ticker\")\n",
    "start_time = datetime.datetime(1980,1,1)\n",
    "end_time = datetime.datetime.now().date()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8ea3f01-5357-4036-8eaa-c738b58e6a00",
   "metadata": {},
   "source": [
    "datetime.datetime.strptime(\n",
    "        my_obj['dttm_utc'],\n",
    "        '%Y-%m-%s %h:%m:%s'\n",
    "    ).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11b2007c-cd89-4aa4-aa7a-f6b28ed8aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker):\n",
    "    df = pdr.get_data_yahoo(ticker, start=start_time, end=end_time)         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d9e2975-9016-4854-a328-45f2bb0d3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ema(df):\n",
    "    df['EMA50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "    #Setting adjust to False to specify that recursive calculation mode is required.\n",
    "    df['EMA100'] = df['Close'].ewm(span=100, adjust=False).mean()\n",
    "    #df['EMA150'] = EMA(df['Close'].values, timeperiod=150)\n",
    "   # df['EMA200'] = EMA(df['Close'].values, timeperiod=200)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8affcc1f-c0e2-4b6d-bbda-e87eaaeeb84d",
   "metadata": {},
   "source": [
    "def computeMACD(df, n_fast, n_slow, n_smooth):\n",
    "    data = df['Close']\n",
    "    fastEMA = data.ewm(span=n_fast, min_periods=n_slow).mean()\n",
    "    slowEMA = data.ewm(span=n_slow, min_periods=n_slow).mean()\n",
    "    MACD = pd.Series(fastEMA-slowEMA, name = 'MACD')\n",
    "    df = df.join(MACD)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beae0bfd-fec4-4524-98dc-d326ccfa47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the MACD indicator\n",
    "#df =computeMACD(df, 12, 26, 9)\n",
    "#The values can be altered along with the model. \n",
    "#The values are normalised between -1 to 1 which is not suitable for the current model\n",
    "#As we are looking for the intersection of price and MACD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e47e9-d836-433c-9d8d-5afc8b0b8919",
   "metadata": {},
   "source": [
    "### Creating the feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5a18923-bfee-4dcc-9963-6c9e321709f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculated_features(df):\n",
    "    df['aboveEMA50'] = np.where(df['Close'] > df['EMA50'], 1, 0)\n",
    "    df['aboveEMA100'] = np.where(df['Close'] > df['EMA100'], 1, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c387324-3879-4a0e-a803-c301bde51823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the DF based on the conditions\n",
    "def defined_conditions(df):\n",
    "    # List of conditions\n",
    "    condition = [(df['aboveEMA50'] == df['aboveEMA100']) & (df['aboveEMA50'] ==1),\n",
    "                 (df['aboveEMA50'] == df['aboveEMA100']) & (df['aboveEMA50'] ==0),\n",
    "                 (df['aboveEMA50'] != df['aboveEMA100'])]\n",
    "    # List of values to return\n",
    "    choice  = [1,0,2]\n",
    "\n",
    "    df['Buy/Sell'] = np.select(condition, choice, \"ERROR\")\n",
    "    \n",
    "    return df\n",
    "#Considering it as a buy if the price is over 50 ema and 100 ema.\n",
    "#Considering it as a Sell if the price is under 50 ema and 100 ema. \n",
    "#Further analysis is required if the price is over 50 ema and under ema 100 or vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48489fda-c34e-4303-90a9-f271fad54781",
   "metadata": {},
   "source": [
    "### Creating DF for multiple stocks and Indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53612069-7c3a-481c-813c-6e1d7cdb6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the stock Data from the user. \n",
    "#tickers = ['AAPL','GOOG','AMD','AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1935c86e-216b-4f87-8907-aae727024971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Calling the get_data function definition. \n",
    "df = get_data(ticker)\n",
    "df = df.reset_index()\n",
    "df = df.set_index('Date')\n",
    "#Calculating EMA 50 and 100\n",
    "df = compute_ema(df)\n",
    "#Calculating if the signal is to buy or sell.\n",
    "df = calculated_features(df)\n",
    "# Rules for placind a trade.\n",
    "df = defined_conditions(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579e68a-41fb-4db8-ad68-5d2389eeff08",
   "metadata": {},
   "source": [
    "### Seperating Labels and Features from the Data frame and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15682b16-d5c9-4e41-9ccf-eac5a5e367bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>EMA100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-07-01</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-02</th>\n",
       "      <td>5.043333</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>5.001699</td>\n",
       "      <td>5.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-03</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>5.001633</td>\n",
       "      <td>5.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-05</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>5.001569</td>\n",
       "      <td>5.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-08</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>900.0</td>\n",
       "      <td>4.988435</td>\n",
       "      <td>4.994207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close   Volume     EMA50    EMA100\n",
       "Date                                             \n",
       "2002-07-01  5.000000   3900.0  5.000000  5.000000\n",
       "2002-07-02  5.043333  21000.0  5.001699  5.000858\n",
       "2002-07-03  5.000000  30600.0  5.001633  5.000841\n",
       "2002-07-05  5.000000   1500.0  5.001569  5.000824\n",
       "2002-07-08  4.666667    900.0  4.988435  4.994207"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns =['Buy/Sell', 'High', 'Low', 'Open', 'Adj Close', 'aboveEMA50', 'aboveEMA100'])\n",
    "#Reviewing features Data Frame.\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "076045b5-79b5-4c03-bb5b-cc37df3298b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2002-07-01    0\n",
       "2002-07-02    1\n",
       "2002-07-03    0\n",
       "2002-07-05    0\n",
       "2002-07-08    0\n",
       "Name: Buy/Sell, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Buy/Sell']\n",
    "#Reviewing Label.\n",
    "y.head(5)\n",
    "#y.value_counts()\n",
    "## Found class Imbalances in the data set. \n",
    "# Suggested to use SMOTE Upsampling to balane the class.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c77df952-36bf-4f6e-9f3c-07421b84de57",
   "metadata": {},
   "source": [
    "smote = SMOTE(random_state=2022)\n",
    "X_s,y_s =smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d191d51a-bd62-40d3-b194-298e7b0aa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5939206e-4a97-4d9a-8cb4-e87c82fe70f6",
   "metadata": {},
   "source": [
    "### Passing the Data to NN to establish a baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bf87b-27d6-42c2-b661-c995ce7dd7ce",
   "metadata": {},
   "source": [
    "#### Normalising the data using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec033b1-e9c7-4fd8-873b-7fc399c6bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale both the training and testing data from the features dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# encoding class labels as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb69032-8a90-405f-a677-8c69f08491ae",
   "metadata": {},
   "source": [
    "#### Adding Layers to Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "633ba7c0-fe44-408d-8811-d217aabf42e8",
   "metadata": {},
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 =  (number_input_features+1)//2\n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1+1)//2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer specifying the number of inputs, the number of hidden nodes, and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Add the second hidden layer specifying the number of hidden nodes and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68fd8ee8-02f5-4b47-ae2f-880c4fdb2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dropout(0.2, input_shape=(4,)))\n",
    "\tmodel.add(Dense(10, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "\tmodel.add(Dense(5, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tsgd = SGD(learning_rate=0.1, momentum=0.9)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\treturn model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "045c04e9-d2c1-4335-99bf-12194928a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(model=create_model, epochs=30, batch_size=1, verbose=0)))\n",
    "pipeline = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8909c300-11b2-4613-a3a6-cb967f3601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a49483c0-de81-48f0-b1ae-d85e335f660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(pipeline, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ad07c9c-be1b-4b49-a298-6a82bced3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible: 31.98% (0.04%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Visible: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "### Additional tune up and Learning rate and Epochs needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440d56a-5625-4f9e-8a24-e4bb98fd5d37",
   "metadata": {},
   "source": [
    "### Creating Ensemble"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a8526cc-eb5b-452a-a006-34d4f0676d67",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# making predictions on the testing set\n",
    "y_pred = gnb.predict(X_test)\n",
    "  \n",
    "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1932a9c2-44e6-4ea7-bda3-9e93e6e480d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6303501945525292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "#clf4 = XGBClassifier()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\n",
    "\n",
    "\n",
    "eclf.fit(X_train, y_train)\n",
    " \n",
    "# predicting the output on the test dataset\n",
    "pred_final = eclf.predict(X_test)\n",
    " \n",
    "# printing log loss between actual and predicted value\n",
    "print(accuracy_score(y_test, pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8261132c-4f59-4158-b4a2-b2fac21c9435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.86 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.62 (+/- 0.02) [Naive Bayes]\n",
      "Accuracy: 0.65 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3,eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbc85ed-270c-44cc-9c85-e821714de38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models to be tuned up for better accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
